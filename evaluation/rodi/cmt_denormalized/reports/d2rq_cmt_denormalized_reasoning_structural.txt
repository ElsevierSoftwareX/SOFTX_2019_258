[ Evaluation report 'Q01 (Persons)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q02 (1st Authors)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q03 (Co-Authors)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q04 (Conferences)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q06 (Reviewers)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q07 (Documents)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q08 (Papers)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q09 (Abstracts)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q11 (Program Committees)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q12 (PC Members)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q14 (PC Chairs)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q20 (Peoples' Complete Names)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q23 (E-mail Addresses)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q25 (Conference Names)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q26 (Start Dates)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q36 (Paper IDs)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q38 (Paper Titles)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q35 (Abstract IDs)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q36 (Abstract Titles)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q40 (Conference URLs, Linked from Conference)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q41 (Papers <-> Authors)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q42 (Papers <-> Co-Authors)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q42b (Papers <-> Co-Authors)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q43 (Papers <-> Reviewers)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q46 (PCs <-> Persons)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'All (AVG)': score = 0.20000001788139343; precision = 0.20000000298023224, recall = 0.20000000298023224]
[ Evaluation report 'path-3 (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'path-2 (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'path-1 (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'n-1 (AVG)': score = 0.25; precision = 0.25, recall = 0.25]
[ Evaluation report 'path-0 (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report '1-1 (AVG)': score = 0.5714285969734192; precision = 0.5714285969734192, recall = 0.5714285969734192]
[ Evaluation report 'attrib (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'in-table (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'link (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'denorm (AVG)': score = 0.1666666716337204; precision = 0.1666666716337204, recall = 0.1666666716337204]
[ Evaluation report 'path-X (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'class (AVG)': score = 0.4545454680919647; precision = 0.4545454680919647, recall = 0.4545454680919647]
