[ Evaluation report 'Q01 (Persons)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q02 (1st Authors)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q03 (Co-Authors)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q04 (Conferences)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q06 (Reviewers)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q07 (Documents)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q08 (Papers)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q09 (Abstracts)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q10 (Reviews)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q11 (Program Committees)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q12 (PC Members)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q14 (PC Chairs)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q20 (Peoples' Complete Names)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q23 (E-mail Addresses)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q25 (Conference Names)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q26 (Start Dates)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q28 (PC Names)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q32 (Paper IDs)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q34 (Paper Titles)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q35 (Abstract IDs)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q36 (Abstract Titles)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q38 (Review Texts)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q40 (Conference URLs, Linked from Conference)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q41 (Papers <-> Authors)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q42 (Papers <-> Co-Authors)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q43 (Papers <-> Reviewers)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q46 (PCs <-> Persons)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'All (AVG)': score = 0.4444444477558136; precision = 0.4444444477558136, recall = 0.4444444477558136]
[ Evaluation report 'path-3 (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'path-2 (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'path-1 (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'n-1 (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report '1-1 (AVG)': score = 0.8571428656578064; precision = 0.8571428656578064, recall = 0.8571428656578064]
[ Evaluation report 'attrib (AVG)': score = 0.5454545617103577; precision = 0.5454545617103577, recall = 0.5454545617103577]
[ Evaluation report 'in-table (AVG)': score = 0.5454545617103577; precision = 0.5454545617103577, recall = 0.5454545617103577]
[ Evaluation report 'link (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'denorm (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'path-X (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'class (AVG)': score = 0.5; precision = 0.5, recall = 0.5]
